import time
import urllib.parse
import requests
from bs4 import BeautifulSoup

# –°–µ–ª–µ–∫—Ç–æ—Ä—ã
NAME = "h1"
DESCRIPTIONS = "meta[itemprop='description']"
DESCRIPTIONS_FULL_PAGE = "[data-marker='item-view/item-description']"
URL = "[itemprop='url']"
PRICE = "[itemprop='price']"
TOTAL_VIEWS = "[data-marker='item-view/total-views']"
PARAMS = "[data-marker='item-view/item-params']"
DATE_PUBLIC = "[data-marker='item-view/item-date']"
SELLER_NAME = "[data-marker='seller-info/label']"
SELLER_LINK = "[data-marker='seller-link/link']"
COMPANY_NAME = "[data-marker='seller-link/link']"
COMPANY_NAME_TEXT = "span"
ADDRESS = "div[class*='style-item-address']"

def send_message_to_telegram(text, tg_token, chat_id):
    """–§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram —Å —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –Ω–∞ —á–∞—Å—Ç–∏"""
    max_length = 4096  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram

    if len(text) <= max_length:
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–æ–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ —Å—Ä–∞–∑—É
        requests.post(
            f'https://api.telegram.org/bot{tg_token}/sendMessage',
            data={'chat_id': chat_id, 'text': text}
        )
    else:
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ –Ω–∞ —á–∞—Å—Ç–∏
        parts = [text[i:i + max_length] for i in range(0, len(text), max_length)]
        for part in parts:
            requests.post(
                f'https://api.telegram.org/bot{tg_token}/sendMessage',
                data={'chat_id': chat_id, 'text': part}
            )

def card_info(thread, driver, total_urls: list, tg_token: str = None, chat_id: str = None, requests_pause: int = 0):
    """–°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–∫–∏"""
    print(f'\n\n{"+" * 25} –ó–ê–ü–£–°–ö –°–ë–û–†–ê –ò–ù–§–û–†–ú–ê–¶–ò–ò –ü–û –ö–ê–†–¢–ï –¢–û–í–ê–†–ê {"+" * 25}\n')
    print("üî∏" * 50 + '\n\n')
    for total_url in total_urls:
        if not thread.running:
            print("‚ö†Ô∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–±–æ—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∫–∞—Ä—Ç–æ—á–∫–∞–º —Ç–æ–≤–∞—Ä–æ–≤...")
            return
        print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {requests_pause} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º...")
        time.sleep(requests_pause)
        driver.get(total_url)

        # –ü–æ–ª—É—á–∞–µ–º –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        while True:
            if not thread.running:
                print("‚ö†Ô∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–±–æ—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∫–∞—Ä—Ç–æ—á–∫–∞–º —Ç–æ–≤–∞—Ä–æ–≤...")
                return

            decoded_html = urllib.parse.unquote(driver.page_source)
            soup = BeautifulSoup(decoded_html, "lxml")
            h2_element = soup.find('h2')

            # –ï—Å–ª–∏ –Ω–µ—Ç <h2> –∏–ª–∏ –≤ –Ω—ë–º –Ω–µ—Ç 'IP' ‚Äî –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
            if not h2_element or 'IP' not in h2_element.text:
                break

            # –ò–Ω–∞—á–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∑–∞—â–∏—Ç–∞ Avito (IP). –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã...")
            driver.refresh()
            time.sleep(3)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π)

        # –ù–∞–∑–≤–∞–Ω–∏–µ
        title_element = soup.select_one(NAME)
        title = title_element.text.strip() if title_element else "–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è"

        # –¶–µ–Ω–∞
        price_element = soup.select_one(PRICE)
        price = price_element.text.strip() if price_element else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"

        # —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        characteristic_element = soup.select_one(PARAMS)
        characteristic = characteristic_element.text if characteristic_element else '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'

        # URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        url_element = soup.select_one(URL)
        url = url_element['content'] if url_element and url_element.has_attr('content') else total_url

        # –û–ø–∏—Å–∞–Ω–∏–µ
        desc_meta = soup.select_one(DESCRIPTIONS_FULL_PAGE).find_all('p')
        description_meta = []
        for d in desc_meta:
            try:
                description_meta.append(d.text)
            except:
                continue
        description_meta = description_meta if description_meta else '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'
        total_views_element = soup.select_one(TOTAL_VIEWS)
        total_views = total_views_element.text.strip() if total_views_element else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

        date_public_element = soup.select_one(DATE_PUBLIC)
        date_public = date_public_element.text.strip() if date_public_element else "–ù–µ—Ç –¥–∞—Ç—ã"

        seller_element = soup.select_one(SELLER_NAME)
        seller_name = seller_element.text.strip() if seller_element else "–ü—Ä–æ–¥–∞–≤–µ—Ü –Ω–µ —É–∫–∞–∑–∞–Ω"

        seller_link_element = soup.select_one(SELLER_LINK)
        seller_link = 'https://www.avito.ru' + seller_link_element[
            'href'] if seller_link_element and seller_link_element.has_attr('href') else "–ù–µ—Ç —Å—Å—ã–ª–∫–∏"

        company_element = soup.select_one(COMPANY_NAME)
        company_name = company_element.text.strip() if company_element else "–ß–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ"

        address_element = soup.select_one(ADDRESS)
        address = address_element.text.strip() if address_element else "–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        unpack_desc = "\n".join(description_meta)
        # –í—ã–≤–æ–¥ –≤ GUI –∏ –∫–æ–Ω—Å–æ–ª—å
        parsed_text = f"""
        <b><font color="yellow">–ù–∞–∑–≤–∞–Ω–∏–µ:</font></b> {title} <br>
        <b><font color="yellow">–¶–µ–Ω–∞:</font></b> {price} <br>
        <b><font color="yellow">–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞:</font></b> {characteristic} <br>
        <b><font color="yellow">–û–ø–∏—Å–∞–Ω–∏–µ:</font></b> {unpack_desc} <br>
        <b><font color="yellow">–ü—Ä–æ—Å–º–æ—Ç—Ä—ã:</font></b> {total_views} <br>
        <b><font color="yellow">–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:</font></b> {date_public} <br>
        <b><font color="yellow">–ü—Ä–æ–¥–∞–≤–µ—Ü:</font></b> {seller_name} <br>
        <b><font color="yellow">–°—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞:</font></b> {seller_link} <br>
        <b><font color="yellow">–ö–æ–º–ø–∞–Ω–∏—è:</font></b> {company_name} <br>
        <b><font color="yellow">–ê–¥—Ä–µ—Å:</font></b> {address} <br>
        <b><font color="yellow">URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è:</font></b> {url}
        """

        print(parsed_text)


        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        parsed_data = {
            "–ù–∞–∑–≤–∞–Ω–∏–µ": title,
            "–¶–µ–Ω–∞": price,
            "–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞": characteristic,
            "–û–ø–∏—Å–∞–Ω–∏–µ": unpack_desc,
            "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": total_views,
            "–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏": date_public,
            "–ü—Ä–æ–¥–∞–≤–µ—Ü": seller_name,
            "–°—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞": seller_link,
            "–ö–æ–º–ø–∞–Ω–∏—è": company_name,
            "–ê–¥—Ä–µ—Å": address,
            "URL": url
        }

        thread.data_collected.emit(parsed_data)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ GUI
        if tg_token:
            # üìå –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Telegram, —Ä–∞–∑–±–∏–≤–∞—è —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏
            send_message_to_telegram(parsed_text, tg_token, chat_id)
        print('                      ')
        print("üî∏" * 50 + '\n\n')

